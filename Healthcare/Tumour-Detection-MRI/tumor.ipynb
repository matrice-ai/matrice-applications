{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install --upgrade matrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "class Vars:\n",
    "    _data = {}\n",
    "    _path = None\n",
    "\n",
    "    @classmethod\n",
    "    def initialize(cls, path):\n",
    "        cls._path = path\n",
    "        cls._data = cls.load()\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls):\n",
    "        if cls._path and os.path.exists(cls._path):\n",
    "            with open(cls._path, 'r') as f:\n",
    "                return yaml.safe_load(f)\n",
    "        return {}\n",
    "\n",
    "    @classmethod\n",
    "    def get(cls, key):\n",
    "        if key not in cls._data:\n",
    "            raise KeyError(f\"Variable {key} not found\")\n",
    "        return cls._data[key]\n",
    "\n",
    "    @classmethod\n",
    "    def set(cls, key, value):\n",
    "        cls._data[key] = value\n",
    "        with open(cls._path, 'w') as f:\n",
    "            yaml.safe_dump(cls._data, f, default_flow_style=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vars.initialize('vars.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vars.set(\"ENV\", \"dev\")\n",
    "Vars.set(\"MATRICE_ACCESS_KEY_ID\", \"IDAZ************MQO6\")\n",
    "Vars.set(\"MATRICE_SECRET_ACCESS_KEY\", \"52VR************ZY5N8\")\n",
    "Vars.set(\"MATRICE_ACCOUNT_NUMBER\", \"227684************7135\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['ENV'] = Vars.get('ENV')\n",
    "access_key = Vars.get('MATRICE_ACCESS_KEY_ID')\n",
    "secret_key = Vars.get('MATRICE_SECRET_ACCESS_KEY')\n",
    "account_number = Vars.get('MATRICE_ACCOUNT_NUMBER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matrice.session import Session\n",
    "from matrice.projects import Projects\n",
    "from matrice.dataset import Dataset\n",
    "from matrice.models import Model\n",
    "from matrice.deployment import Deployment\n",
    "from matrice.exported_model import ExportedModel\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_instance = Session.create_session(account_number=account_number, access_key=access_key, secret_key=secret_key)\n",
    "print(\"A Session has been initialized:\", session_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_list, msg = session_instance.list_projects(project_type=\"classification\")\n",
    "\n",
    "# Check if there is a message or error\n",
    "if msg:\n",
    "    print(f\"Message: {msg}\")\n",
    "\n",
    "# Print the projects in a formatted manner\n",
    "for project_name, project_instance in projects_list.items():\n",
    "    print(f\"Project Name: {project_name} | Project ID: {project_instance.project_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"Tumor-Classification-Project\"\n",
    "for name, project_instance in projects_list.items():\n",
    "    if name == project_name:\n",
    "        projects_instance = Projects(session_instance, project_name=project_name)\n",
    "        session_instance.update(projects_instance.project_id)\n",
    "        print(f\"Project '{project_name}' already exists. Initialized Projects instance.\")\n",
    "        project_exists = True\n",
    "        break\n",
    "    else:\n",
    "        project_exists = False\n",
    "\n",
    "if project_exists == False:\n",
    "    print(f\"Creating a new project: {project_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "name = \"Tumor-Classification-Project\"\n",
    "\n",
    "# Function to create a project\n",
    "def create_project():\n",
    "    project_name = name\n",
    "    input_type = \"image\"\n",
    "    output_type = \"classification\"\n",
    "    \n",
    "    enabled_platforms = {\n",
    "        \"matrice\": True,\n",
    "        \"android\": False,\n",
    "        \"ios\": False,\n",
    "        \"tpu\": False,\n",
    "        \"intelCPU\": False,\n",
    "        \"gcloudGPU\": False\n",
    "    }\n",
    "\n",
    "    resp, error = session_instance._create_project(project_name, input_type, output_type)\n",
    "    if error:\n",
    "        print(f\"Error: {error}\")\n",
    "        return None, None\n",
    "    else:\n",
    "        print(f\"Project created with ID: {resp['_id']}\")\n",
    "        return resp['_id'], resp['name']\n",
    "\n",
    "# Check if project_id and project_name exist\n",
    "project_id = None\n",
    "project_name = None\n",
    "\n",
    "if not project_exists:\n",
    "    project_id, project_name = create_project()\n",
    "else:\n",
    "    project_id = projects_instance.project_id\n",
    "    project_name = projects_instance.project_name\n",
    "    print(f\"Project already exists with ID: {project_id} and Name: {project_name}\")\n",
    "\n",
    "\n",
    "print(\"----------------------------\")\n",
    "print(f\"Project ID: {project_id}\")\n",
    "print(f\"Project Name: {project_name}\")\n",
    "print(\"----------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vars.set(\"project_name\",project_name)\n",
    "Vars.set(\"project_id\", project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_instance.update(project_id)\n",
    "project_instance = Projects(session_instance, project_name=project_name)\n",
    "print(\"A Project class has been initialized\",project_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, dataset_action = project_instance.import_local_dataset(\n",
    "    dataset_name='Tumor-Dataset',\n",
    "    file_path = r\"C:\\Users\\pathi\\OneDrive\\Desktop\\matriceai\\matrice_usecases_local\\datasets\\tumour_dataset_1.zip\",\n",
    "    dataset_type = \"classification\",\n",
    "    dataset_description = \"Dataset of Tumour Images\",\n",
    "    version_description = \"1st version\",\n",
    "    input_type = \"image\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = dataset.dataset_id\n",
    "action_id = dataset_action.action_id\n",
    "\n",
    "print(f\"Dataset ID: {dataset_id}\")\n",
    "print(f\"Action ID: {action_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vars.set(\"dataset_id\", dataset.dataset_id)\n",
    "Vars.set(\"dataset_action_id\", dataset_action.action_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pprint\n",
    "\n",
    "action_id = dataset_action.action_id\n",
    "def check_dataset_status():\n",
    "    while True:\n",
    "        print(\" \")\n",
    "        print(\"-------Status------\")\n",
    "        D = Dataset(session_instance, dataset_id=dataset_id)\n",
    "        status = D.version_status\n",
    "        print(\"Status of dataset:\", status)\n",
    "        print(\"-------------------\")\n",
    "        if status == 'processed':\n",
    "            print(\"---------Preprocesing Complete---------\")\n",
    "            print(\"Dataset processed, proceed with experiment creation.\")\n",
    "            print(\"---------------------------------------\")\n",
    "            break\n",
    "        \n",
    "        time.sleep(90)  # Wait for 90 seconds before checking again\n",
    "\n",
    "# Run the function to check dataset status\n",
    "check_dataset_status()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dataset_info(dataset):\n",
    "   \n",
    "    dataset_id = dataset.dataset_details['_id']\n",
    "    dataset_name = dataset.dataset_details['name']\n",
    "    version_status = dataset.dataset_details.get(\"stats\", [{}])[0].get(\"versionStatus\")\n",
    "    latest_version = dataset.dataset_details['latestVersion']\n",
    "    no_of_samples = sum(version['versionStats']['total'] for version in dataset.dataset_details.get('stats', []))\n",
    "    no_of_classes = len(dataset.dataset_details.get('stats', [{}])[0].get('classStat', {}))\n",
    "    no_of_versions = len(dataset.dataset_details.get('allVersions', []))\n",
    "    last_updated_at = dataset.dataset_details.get('updatedAt')\n",
    "\n",
    "    print(f\"Dataset ID: {dataset_id}\")\n",
    "    print(f\"Dataset Name: {dataset_name}\")\n",
    "    print(f\"Version Status: {version_status}\")\n",
    "    print(f\"Latest Version: {latest_version}\")\n",
    "    print(f\"Number of Samples: {no_of_samples}\")\n",
    "    print(f\"Number of Classes: {no_of_classes}\")\n",
    "    print(f\"Number of Versions: {no_of_versions}\")\n",
    "    print(f\"Last Updated At: {last_updated_at}\")\n",
    "\n",
    "dataset.refresh()   \n",
    "print_dataset_info(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_summary = dataset.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import plotly.io as pio\n",
    "\n",
    "\n",
    "# Convert the histogram data to a DataFrame\n",
    "df = pd.DataFrame(dataset_summary['histogram'])\n",
    "\n",
    "# Bar chart for counts by category\n",
    "fig1 = go.Figure(data=[go.Bar(x=df['label'], y=df['count'])])\n",
    "fig1.update_layout(\n",
    "    title='Count of Items by Category',\n",
    "    xaxis_title='Category',\n",
    "    yaxis_title='Count'\n",
    ")\n",
    "\n",
    "# Pie chart for distribution of data items\n",
    "fig2 = go.Figure(data=[go.Pie(\n",
    "    labels=['Test', 'Train', 'Unassigned', 'Validation'],\n",
    "    values=[dataset_summary['testDataItemCount'], dataset_summary['trainDataItemCount'], dataset_summary['unassignedDataItemCount'], dataset_summary['valDataItemCount']],\n",
    "    hole=0.3\n",
    ")])\n",
    "fig2.update_layout(\n",
    "    title='Distribution of Data Items'\n",
    ")\n",
    "\n",
    "# Display the figures\n",
    "fig1.show()\n",
    "fig2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pprint\n",
    "import uuid\n",
    "\n",
    "# Generate a unique experiment name\n",
    "unique_experiment_name = \"Tumor-Classification-Experiment\"\n",
    "\n",
    "# Function to create an experiment\n",
    "def create_experiment():\n",
    "    name = unique_experiment_name\n",
    "    target_run_time = [\"PyTorch\"]\n",
    "    primary_metric = \"acc@1\"\n",
    "    matrice_compute = True\n",
    "    dataset_version = 'v1.0'\n",
    "\n",
    "    experiment_instance = project_instance.create_experiment(\n",
    "        name,\n",
    "        dataset_id,\n",
    "        target_run_time[0],\n",
    "        dataset_version,\n",
    "        primary_metric,\n",
    "        matrice_compute\n",
    "    )\n",
    "\n",
    "    print(experiment_instance)\n",
    "    experiment_id = experiment_instance.experiment_id\n",
    "    experiment_name = experiment_instance.experiment_name\n",
    "\n",
    "    print(f\"Experiment ID: {experiment_id}\")\n",
    "    print(f\"Experiment Name: {experiment_name}\")\n",
    "\n",
    "    return experiment_instance, experiment_id, experiment_name\n",
    "\n",
    "# Create a new experiment\n",
    "experiment_instance , experiment_id, experiment_name = create_experiment()\n",
    "\n",
    "print(\"----------------------------\")\n",
    "print(f\"Experiment ID: {experiment_id}\")\n",
    "print(f\"Experiment Name: {experiment_name}\")\n",
    "print(f\"Experiment instance has been created: {experiment_instance}\")\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vars.set(\"experiment_id\", experiment_instance.experiment_id)\n",
    "Vars.set(\"experiment_name\", experiment_instance.experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matrice.model_store import _get_all_model_families \n",
    "\n",
    "resp , error , mesage = _get_all_model_families( session_instance , project_id , project_type=\"classification\" )\n",
    "print(\"----List of available Detection models on platform----\")\n",
    "# Iterate through each model family in the response\n",
    "for model_family in resp:\n",
    "    # Extract _id and modelFamily (model family name)\n",
    "    model_family_id = model_family.get('_id')\n",
    "    name = model_family.get('modelFamily')\n",
    "    \n",
    "    # Print in formatted manner\n",
    "    print(f\"ID: {model_family_id}, Model Family Name: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matrice.model_store import ModelFamily\n",
    "\n",
    "model_family_id = \"66952b5e9bbb09931616d518\"\n",
    "# Initialize the ModelFamily instance after choosing a Model Family\n",
    "model_family_instance = ModelFamily(session_instance, model_family_id=model_family_id) # ResNet\n",
    "print(\"A ModelFamily instance has been initialized\",model_family_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch model architectures\n",
    "import pprint\n",
    "arch_resp, error, message = model_family_instance.get_model_archs()\n",
    "if error:\n",
    "    print(f\"Error: {error}\")\n",
    "else:\n",
    "    pprint.pprint(arch_resp)\n",
    "    # Check if resp is a list or a dictionary\n",
    "    if isinstance(arch_resp, list):\n",
    "        # Iterate through each model info in the list\n",
    "        for model_info in arch_resp:\n",
    "            model_key = model_info[\"model_key\"]\n",
    "            model_arch_instance = model_info[\"model_arch_instance\"]\n",
    "            \n",
    "            # Extract model information\n",
    "            model_info_id = model_arch_instance.model_info_id\n",
    "            name = model_arch_instance.model_name\n",
    "            key = model_arch_instance.model_key\n",
    "            params = model_arch_instance.params_millions\n",
    "\n",
    "            # Print in formatted manner\n",
    "            print(f\"ID: {model_info_id} |  Model Name: {name} | Model Key: {key} | Params in Millions: {params}\")\n",
    "            \n",
    "    elif isinstance(arch_resp, dict):\n",
    "        # Iterate through each model key in the dictionary\n",
    "        for model_key, model_arch_instance in arch_resp.items():\n",
    "            # Extract model information\n",
    "            model_info_id = model_arch_instance.model_info_id\n",
    "            name = model_arch_instance.model_name\n",
    "            key = model_arch_instance.model_key\n",
    "            params = model_arch_instance.params_millions\n",
    "\n",
    "            # Print in formatted manner\n",
    "            print(f\"ID: {model_info_id} | Model Name: {name} | Model Key: {key} | Params in Millions: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matrice.model_store import ModelArch\n",
    "train_arch = 'resnet50' \n",
    "print(\"Chosen Training Architecture :\" ,train_arch)\n",
    "model_arch_instance = arch_resp.get(train_arch)\n",
    "print(\"Model Architecture instance initialized for chosen training architecture :\", model_arch_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "train_instance , train_config = model_arch_instance.get_train_config(experiment_id=Vars.get('experiment_id'))\n",
    "print(\"-----Default Train Config------\")\n",
    "pprint.pprint(train_config)\n",
    "print(\"--------------------------------\")\n",
    "print(\"-------Training instance initialized--------\")\n",
    "print(train_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = train_config['model_config']\n",
    "\n",
    "# Modify the model_config as needed\n",
    "# modifications:\n",
    "model_config['batch'] = [8]\n",
    "model_config['epochs'] = [50]\n",
    "\n",
    "\n",
    "\n",
    "# Repass the modified model_config into the train_config\n",
    "train_config['model_config'] = model_config\n",
    "\n",
    "# Print the updated train_config\n",
    "print(\"-----Updated Model Config------\")\n",
    "pprint.pprint(train_config['model_config'])\n",
    "print(\"--------------------------------\")\n",
    "\n",
    "# Print the updated train_config\n",
    "print(\"-----Updated Train Config------\")\n",
    "pprint.pprint(train_config)\n",
    "print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_resp , msg , err = experiment_instance.add_models_for_training(train_instance,train_config)\n",
    "print(\"------------Model added for training----------\")\n",
    "pprint.pprint(train_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from matrice.action import Action\n",
    "\n",
    "# Define the action ID and the status you want to check\n",
    "action_id = train_resp[0]['_idActionStatus']\n",
    "success_status = 'SUCCESS'\n",
    "\n",
    "# Function to check the status of the action\n",
    "def check_action_status(S, action_id):\n",
    "    action_instance = Action(S, action_id)\n",
    "    print(\"---------------------\")\n",
    "    print(f\"Action ID: {action_id}\")\n",
    "    print(f\"Current Status: {action_instance.status}\")\n",
    "    print(f\"Step Code: {action_instance.step_code}\")\n",
    "    print(f\"Action service is : {action_instance.service_name}\")\n",
    "    print(\"---------------------\")\n",
    "    return action_instance.status\n",
    "\n",
    "# Loop to check status every 2 minutes until it is 'success'\n",
    "while True:\n",
    "    status = check_action_status(session_instance, action_id)\n",
    "    if status == success_status:\n",
    "        print(\"Action status is 'success'. Model is successfully trained.\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"Model is training. Waiting 10 minutes before checking again.\")\n",
    "        time.sleep(400)  # Wait for 10 minutes (600 seconds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = train_resp[0]['_id']\n",
    "print(f\"Model ID from response data: {model_id}\")\n",
    "    \n",
    "\n",
    "# Initialize the Model class with the model_id\n",
    "model_instance = Model(session_instance, model_id)\n",
    "print(\"A Model instance has been initialized : \", model_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the test score, validation score, and best epoch\n",
    "print(f\"Test Score: {model_instance.test_score}\")\n",
    "print(f\"Validation Score: {model_instance.val_score}\")\n",
    "print(f\"Best Epoch: {model_instance.best_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vars.set(\"model_train_id\", model_instance.model_id)\n",
    "Vars.set(\"model_train_name\", model_instance.model_train_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instance.plot_epochs_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instance.plot_epochs_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instance.plot_eval_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import requests\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "# Define the folder path containing the images\n",
    "folder_path = r\"C:\\Users\\pathi\\OneDrive\\Desktop\\matriceai\\matrice_usecases_local\\datasets\\test\"\n",
    "\n",
    "\n",
    "# Get a list of all image files in the folder\n",
    "image_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Randomly select 10 images from the folder\n",
    "random_images = random.sample(image_files, 2)\n",
    "\n",
    "print(random_images)\n",
    "# Loop through the selected images and make predictions\n",
    "for image_file in random_images:\n",
    "    # Get the prediction results from the model\n",
    "    result, error, _ = model_instance.get_prediction(image_file)\n",
    "    print(result)\n",
    "    if error:\n",
    "        print(f\"Error: {error}\")\n",
    "        continue\n",
    "    \n",
    "    # Extract the predicted class label and confidence\n",
    "    predicted_class = result[\"category\"]\n",
    "    confidence = result[\"confidence\"]\n",
    "    \n",
    "    # Open the image\n",
    "    image = Image.open(image_file)\n",
    "    \n",
    "    # Create a matplotlib figure and axis\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    fig, ax = plt.subplots(1)\n",
    "    \n",
    "    # Display the image\n",
    "    ax.imshow(image)\n",
    "    \n",
    "    # Add the predicted class label and confidence to the image\n",
    "    plt.text(10, 10, f\"{predicted_class} ({confidence:.2f})\", bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "    \n",
    "    # Display the image with the annotation\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instance.download_model(file_name=\"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_config = train_instance.get_default_export_config(\"ONNX\") # Get the default export config for export format user wants (here ONNX)\n",
    "print(\"Export Config for ONNX:\")\n",
    "pprint.pprint(export_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_instance , action_instance = project_instance.create_model_export(model_id,\"ONNX\",export_config)\n",
    "\n",
    "print(\"Model Export class has been initialized :\", exported_instance )   \n",
    "print(\"----------------------------\")\n",
    "print(f\"Export ID: {exported_instance.model_export_id}\")\n",
    "print(f\"Export Name: {exported_instance.model_export_name}\")\n",
    "print(f\"Action ID: {action_instance.action_id}\")\n",
    "print(f\"Action Status: {action_instance.status}\")\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vars.set(\"model_export_id\", exported_instance.model_export_id)\n",
    "Vars.set(\"model_export_name\", exported_instance.model_export_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from matrice.action import Action\n",
    "\n",
    "# Define the action ID and the status you want to check\n",
    "action_id = action_instance.action_id\n",
    "success_status = 'SUCCESS'\n",
    "\n",
    "# Function to check the status of the action\n",
    "def check_action_status(S, action_id):\n",
    "    A = Action(S, action_id)\n",
    "    print(\"---------------------\")\n",
    "    print(f\"Action ID: {action_id}\")\n",
    "    print(f\"Current Status: {A.status}\")\n",
    "    print(f\"Step Code: {A.step_code}\")\n",
    "    print(f\"Action service is : {A.service_name}\")\n",
    "    print(\"---------------------\")\n",
    "    return A.status\n",
    "\n",
    "# Loop to check status every 1.5 minutes until it is 'success'\n",
    "while True:\n",
    "    status = check_action_status(session_instance, action_id)\n",
    "    if status == success_status:\n",
    "        print(\"Action status is 'success'. Model is successfully exported.\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"Model is exporting. Waiting 2 minutes before checking again.\")\n",
    "        time.sleep(90)  # Wait for 1.5 minutes (90 seconds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_instance.download_model(file_name=\"model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment , deployment_action = project_instance.create_deployment(\n",
    "    model_id = Vars.get('model_export_id'),  # It can also be model_train_id depending on the model you want to deploy\n",
    "    deployment_name = \"deployment_name\",\n",
    "    shutdown_threshold=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_resp = deployment.create_auth_key()\n",
    "auth_key = key_resp['key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vars.set(\"deployment_id\", deployment.deployment_id)\n",
    "Vars.set(\"deployment_name\", deployment.deployment_name)\n",
    "Vars.set(\"auth_key\", auth_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import requests\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "# Define the folder path containing the images\n",
    "folder_path = r\"<path_to_test_folder>\"\n",
    "\n",
    "\n",
    "# Get a list of all image files in the folder\n",
    "image_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Randomly select 10 images from the folder\n",
    "random_images = random.sample(image_files, 10)\n",
    "\n",
    "\n",
    "# Loop through the selected images and send the prediction request\n",
    "for image_file in random_images:\n",
    "    \n",
    "    result, error, message = deployment.get_prediction(auth_key,image_file)\n",
    "\n",
    "    if error:\n",
    "        print(f\"Error: {error}\")\n",
    "        continue\n",
    "\n",
    "    # Extract prediction data from the result\n",
    "    predictions = result\n",
    "\n",
    "    # Open the image\n",
    "    image = Image.open(image_file)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.imshow(image)\n",
    "\n",
    "    # Draw bounding boxes and labels\n",
    "    for prediction in predictions:\n",
    "        category = prediction[\"category\"]\n",
    "        confidence = prediction[\"confidence\"]\n",
    "        bbox = prediction[\"bounding_box\"]\n",
    "\n",
    "        # Extract the bounding box coordinates\n",
    "        xmin, ymin, xmax, ymax = bbox[\"xmin\"], bbox[\"ymin\"], bbox[\"xmax\"], bbox[\"ymax\"]\n",
    "        width, height = xmax - xmin, ymax - ymin\n",
    "\n",
    "        # Create a Rectangle patch\n",
    "        rect = plt.Rectangle((xmin, ymin), width, height, linewidth=2, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        plt.text(xmin, ymin, f\"{category} ({confidence:.2f})\", bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
