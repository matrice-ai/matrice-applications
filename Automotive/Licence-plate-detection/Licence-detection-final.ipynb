{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7byzuL9-woSy"
      },
      "source": [
        "## Install the matrice package or upgrade it if already installed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzbINaiGwoS0"
      },
      "outputs": [],
      "source": [
        "#!python -m pip install --upgrade --index-url https://test.pypi.org/simple/ --no-deps matrice\n",
        "#!python -m pip install --upgrade matrice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqUhIUHmwoS2"
      },
      "outputs": [],
      "source": [
        "!python -m pip install --upgrade matrice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwqWJWKfwoS2"
      },
      "source": [
        "## Install required dependencies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets"
      ],
      "metadata": {
        "id": "DaC7566v1yBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92Yf8VG5woS3"
      },
      "outputs": [],
      "source": [
        "!pip install pycocotools pyyaml seaborn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9ZsnHnzwoS3"
      },
      "source": [
        "## Setting up the credentials\n",
        "*   ENV\n",
        "*   MATRICE_ACCESS_KEY_ID\n",
        "*   MATRICE_SECRET_ACCESS_KEY\n",
        "*   MATRICE_ACCOUNT_NUMBER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FnrSEY0woS4"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "import os\n",
        "\n",
        "class Vars:\n",
        "    _data = {}\n",
        "    _path = None\n",
        "\n",
        "    @classmethod\n",
        "    def initialize(cls, path):\n",
        "        cls._path = path\n",
        "        cls._data = cls.load()\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls):\n",
        "        if cls._path and os.path.exists(cls._path):\n",
        "            with open(cls._path, 'r') as f:\n",
        "                return yaml.safe_load(f)\n",
        "        return {}\n",
        "\n",
        "    @classmethod\n",
        "    def get(cls, key):\n",
        "        if key not in cls._data:\n",
        "            raise KeyError(f\"Variable {key} not found\")\n",
        "        return cls._data[key]\n",
        "\n",
        "    @classmethod\n",
        "    def set(cls, key, value):\n",
        "        cls._data[key] = value\n",
        "        with open(cls._path, 'w') as f:\n",
        "            yaml.safe_dump(cls._data, f, default_flow_style=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ka9pB92woS5"
      },
      "outputs": [],
      "source": [
        "Vars.initialize('vars.yaml')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4u1F8TcewoS5"
      },
      "outputs": [],
      "source": [
        "Vars.set(\"ENV\", \"prod\")\n",
        "Vars.set(\"MATRICE_ACCESS_KEY_ID\", \"YU9OZ4AE*******GM8R6H\")\n",
        "Vars.set(\"MATRICE_SECRET_ACCESS_KEY\", \"8DBFKOIMG*******0V9B5\")\n",
        "Vars.set(\"MATRICE_ACCOUNT_NUMBER\", \"549019934232*******03509\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkGPBjAbwoS6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['ENV'] = Vars.get('ENV')\n",
        "access_key = Vars.get('MATRICE_ACCESS_KEY_ID')\n",
        "secret_key = Vars.get('MATRICE_SECRET_ACCESS_KEY')\n",
        "account_number = Vars.get('MATRICE_ACCOUNT_NUMBER')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y15_qaawoS6"
      },
      "source": [
        "## Import required matrice modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scNvA__0woS7"
      },
      "outputs": [],
      "source": [
        "from matrice.session import Session\n",
        "from matrice.projects import Projects\n",
        "from matrice.dataset import Dataset\n",
        "from matrice.models import Model\n",
        "from matrice.deployment import Deployment\n",
        "from matrice.exported_model import ExportedModel\n",
        "import sys\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noj6S7JBwoS7"
      },
      "source": [
        "# Create Object Detection Project with Matrice SDK\n",
        "\n",
        "1.   Initialize matrice connection session\n",
        "2.   List projects in user account\n",
        "3.   Create the Project\n",
        "4.   Update the session with the project_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfcANbHqwoS7"
      },
      "outputs": [],
      "source": [
        "session_instance = Session.create_session(account_number=account_number, access_key=access_key, secret_key=secret_key)\n",
        "print(\"A Session has been initialized:\", session_instance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRrdoKnawoS7"
      },
      "outputs": [],
      "source": [
        "projects_list, msg = session_instance.list_projects(project_type=\"detection\")\n",
        "\n",
        "# Check if there is a message or error\n",
        "if msg:\n",
        "    print(f\"Message: {msg}\")\n",
        "\n",
        "# Print the projects in a formatted manner\n",
        "for project_name, project_instance in projects_list.items():\n",
        "    print(f\"Project Name: {project_name} | Project ID: {project_instance.project_id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePw0U1jgwoS8"
      },
      "outputs": [],
      "source": [
        "project_name = \"Vehicles-licence-plate-detection\"\n",
        "for name, project_instance in projects_list.items():\n",
        "    if name == project_name:\n",
        "        projects_instance = Projects(session_instance, project_name=project_name)\n",
        "        session_instance.update(projects_instance.project_id)\n",
        "        print(f\"Project '{project_name}' already exists. Initialized Projects instance.\")\n",
        "        project_exists = True\n",
        "        break\n",
        "    else:\n",
        "        project_exists = False\n",
        "\n",
        "if project_exists == False:\n",
        "    print(f\"Creating a new project: {project_name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InFJiydpwoS8"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "name = \"Vehicles-licence-plate-detection\"\n",
        "# Function to create a project\n",
        "def create_project():\n",
        "    project_name = name\n",
        "    input_type = \"image\"\n",
        "    output_type = \"detection\"\n",
        "\n",
        "    enabled_platforms = {\n",
        "        \"matrice\": True,\n",
        "        \"android\": False,\n",
        "        \"ios\": False,\n",
        "        \"tpu\": False,\n",
        "        \"intelCPU\": False,\n",
        "        \"gcloudGPU\": False\n",
        "    }\n",
        "\n",
        "    resp, error = session_instance._create_project(project_name, input_type, output_type)\n",
        "    if error:\n",
        "        print(f\"Error: {error}\")\n",
        "        return None, None\n",
        "    else:\n",
        "        print(f\"Project created with ID: {resp['_id']}\")\n",
        "        return resp['_id'], resp['name']\n",
        "\n",
        "# Check if project_id and project_name exist\n",
        "project_id = None\n",
        "project_name = None\n",
        "\n",
        "if not project_exists:\n",
        "    project_id, project_name = create_project()\n",
        "else:\n",
        "    project_id = projects_instance.project_id\n",
        "    project_name = projects_instance.project_name\n",
        "    print(f\"Project already exists with ID: {project_id} and Name: {project_name}\")\n",
        "\n",
        "\n",
        "print(\"----------------------------\")\n",
        "print(f\"Project ID: {project_id}\")\n",
        "print(f\"Project Name: {project_name}\")\n",
        "print(\"----------------------------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZfnRygUwoS8"
      },
      "outputs": [],
      "source": [
        "Vars.set(\"project_name\",project_name)\n",
        "Vars.set(\"project_id\", project_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qjf19oEXwoS8"
      },
      "outputs": [],
      "source": [
        "session_instance.update(project_id)\n",
        "project_instance = Projects(session_instance, project_name=project_name)\n",
        "print(\"A Project class has been initialized\",project_instance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PF6LSq7woS9"
      },
      "source": [
        "# Preparing the Dataset\n",
        "\n",
        "\n",
        "1.   Dataset Downlaod (either local download or use scripts to download)\n",
        "2.   Dataset Exploration\n",
        "3.   Plot Samples from the Dataset\n",
        "4.   Dataset Format Preparation in MSCOCO\n",
        "5.   Compress the Dataset to be ready for uploading"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from opendatasets import download\n",
        "download(\"https://www.kaggle.com/datasets/amirhoseinahmadnejad/car-license-plate-detection-iran\")"
      ],
      "metadata": {
        "id": "nskxuikD1sK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Load COCO JSON file\n",
        "with open('/content/car-license-plate-detection-iran/train/_annotations.coco.json', 'r') as f:\n",
        "    coco_data = json.load(f)\n",
        "\n",
        "# Extract relevant information\n",
        "annotations = coco_data['annotations']\n",
        "images = coco_data['images']\n",
        "categories = coco_data['categories']\n",
        "\n",
        "# Convert annotations to DataFrame\n",
        "df_annotations = pd.DataFrame(annotations)\n",
        "\n",
        "# Convert images to DataFrame\n",
        "df_images = pd.DataFrame(images)\n",
        "\n",
        "# Merge annotations and images based on image_id\n",
        "df = pd.merge(df_annotations, df_images, left_on='image_id', right_on='id')\n",
        "\n",
        "# Add region_count by counting occurrences of each image in the annotations\n",
        "df['region_count'] = df.groupby('image_id')['image_id'].transform('count')\n",
        "\n",
        "# Inspect the DataFrame\n",
        "df.head()"
      ],
      "metadata": {
        "id": "PHw_1BXm2P3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Visualize region counts by category (you may need to adjust this if different structure)\n",
        "category_counts = df['category_id'].value_counts()\n",
        "\n",
        "# Plot the counts\n",
        "category_counts.plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
        "plt.gca().spines[['top', 'right']].set_visible(False)\n",
        "plt.title(\"Category Counts\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jP2FnePK2YTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop duplicates and keep unique images\n",
        "df_unique = df.drop_duplicates(subset=['file_name'])\n",
        "\n",
        "# Plot histogram of region counts\n",
        "df_unique['region_count'].plot(kind='hist', bins=20, title='Region Count per Image')\n",
        "plt.gca().spines[['top', 'right']].set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OChYmLMg2baf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import json\n",
        "\n",
        "def plot_samples_from_coco(df_annotations, df_images, num_samples, image_path, images_per_row=3):\n",
        "    \"\"\"\n",
        "    Plots bounding boxes from COCO annotations on the specified images side by side with reduced spacing.\n",
        "\n",
        "    Parameters:\n",
        "    - df_annotations: DataFrame containing the COCO annotations\n",
        "    - df_images: DataFrame containing the COCO image details (file names, IDs)\n",
        "    - num_samples: Number of the file names to plot\n",
        "    - image_path: Path to the directory containing the image files\n",
        "    - images_per_row: Number of images to display per row\n",
        "    \"\"\"\n",
        "    # Ensure num_samples does not exceed the number of unique filenames in the DataFrame\n",
        "    unique_file_names = df_images['file_name'].unique()\n",
        "    num_samples = min(num_samples, len(unique_file_names))\n",
        "\n",
        "    # Randomly sample file names\n",
        "    file_names = np.random.choice(unique_file_names, num_samples, replace=False)\n",
        "    num_images = len(file_names)\n",
        "    num_rows = int(np.ceil(num_images / images_per_row))\n",
        "\n",
        "    # Create a figure with subplots\n",
        "    fig, axes = plt.subplots(num_rows, images_per_row, figsize=(images_per_row * 4, num_rows * 4), squeeze=False)\n",
        "    if num_rows == 1:\n",
        "        axes = np.array(axes).reshape(1, -1)\n",
        "\n",
        "    for i, file_name in enumerate(file_names):\n",
        "        # Get the image ID from df_images using file_name\n",
        "        img_data = df_images[df_images['file_name'] == file_name].iloc[0]\n",
        "        image_id = img_data['id']\n",
        "\n",
        "        # Load the image\n",
        "        full_image_path = f'{image_path}/{file_name}'\n",
        "        img = Image.open(full_image_path)\n",
        "\n",
        "        # Filter the annotations for this image\n",
        "        img_ann = df_annotations[df_annotations['image_id'] == image_id]\n",
        "\n",
        "        # Select the correct subplot\n",
        "        ax = axes[i // images_per_row, i % images_per_row]\n",
        "\n",
        "        # Show the image\n",
        "        ax.imshow(img)\n",
        "\n",
        "        # Plot each bounding box\n",
        "        for _, row in img_ann.iterrows():\n",
        "            # COCO stores bounding boxes as [x, y, width, height]\n",
        "            bbox = row['bbox']\n",
        "            x, y, width, height = bbox\n",
        "            category_id = row['category_id']\n",
        "\n",
        "            # Set rectangle color based on category (you can customize it as needed)\n",
        "            edge_color = 'r' if category_id == 1 else 'g'\n",
        "\n",
        "            # Create and add the rectangle to the plot\n",
        "            rect = patches.Rectangle((x, y), width, height, linewidth=1, edgecolor=edge_color, facecolor='none')\n",
        "            ax.add_patch(rect)\n",
        "\n",
        "            # Optionally add a label (category or any other info)\n",
        "            ax.text(x, y - 10, f'Category {category_id}', color=edge_color, fontsize=10, weight='bold')\n",
        "\n",
        "        # Remove axis for better visualization\n",
        "        ax.axis('off')\n",
        "        # Set the title with the file name\n",
        "        ax.set_title(file_name, fontsize=8)\n",
        "\n",
        "    # Turn off any unused subplots\n",
        "    for j in range(num_images, num_rows * images_per_row):\n",
        "        axes.flatten()[j].axis('off')\n",
        "\n",
        "    # Adjust layout to prevent overlap and reduce spacing\n",
        "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "4TdEZEvU2kDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load COCO JSON file\n",
        "with open('/content/car-license-plate-detection-iran/train/_annotations.coco.json', 'r') as f:\n",
        "    coco_data = json.load(f)\n",
        "\n",
        "# Convert annotations and images sections to DataFrames\n",
        "df_annotations = pd.DataFrame(coco_data['annotations'])\n",
        "df_images = pd.DataFrame(coco_data['images'])\n",
        "\n",
        "# Ensure bbox is a proper list format\n",
        "df_annotations['bbox'] = df_annotations['bbox'].apply(lambda x: x if isinstance(x, list) else json.loads(x))\n",
        "plot_samples_from_coco(df_annotations, df_images, num_samples=6, image_path='/content/car-license-plate-detection-iran/train')"
      ],
      "metadata": {
        "id": "sgR6U5Ga2oS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/car-license-plate-detection-iran_mscoco"
      ],
      "metadata": {
        "id": "BpKpUiw-604J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KIXXrbOwoS9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Paths for source dataset and target dataset\n",
        "src_dir = '/content/car-license-plate-detection-iran'\n",
        "dst_dir = 'car-license-plate-detection-iran_mscoco'\n",
        "\n",
        "# Define paths for images and annotations\n",
        "images_dir = os.path.join(dst_dir, 'images')\n",
        "annotations_dir = os.path.join(dst_dir, 'annotations')\n",
        "\n",
        "# Create target directories for images and annotations\n",
        "os.makedirs(os.path.join(images_dir, 'train'), exist_ok=True)\n",
        "os.makedirs(os.path.join(images_dir, 'test'), exist_ok=True)\n",
        "os.makedirs(os.path.join(images_dir, 'valid'), exist_ok=True)\n",
        "os.makedirs(annotations_dir, exist_ok=True)\n",
        "\n",
        "# Mapping of original folders to new paths\n",
        "splits = ['train', 'test', 'valid']\n",
        "\n",
        "# Loop over each split and copy files\n",
        "for split in splits:\n",
        "    src_split_dir = os.path.join(src_dir, split)\n",
        "    dst_split_dir = os.path.join(images_dir, split)\n",
        "\n",
        "    # Copy all image files\n",
        "    for item in os.listdir(src_split_dir):\n",
        "        item_path = os.path.join(src_split_dir, item)\n",
        "        if os.path.isfile(item_path) and item.endswith(('.jpg', '.jpeg', '.png')):\n",
        "            shutil.copy(item_path, os.path.join(dst_split_dir, item))\n",
        "        elif item == '_annotations.coco.json':\n",
        "            # Copy and rename the annotations file\n",
        "            shutil.copy(item_path, os.path.join(annotations_dir, f'{split}.json'))\n",
        "\n",
        "print(\"Dataset conversion complete with copied files!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hXfBoFLwoS-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "def zip_dataset(folder_path, output_zip):\n",
        "    # Create the zip file\n",
        "    with zipfile.ZipFile(output_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        # Walk through the directory\n",
        "        for root, dirs, files in os.walk(folder_path):\n",
        "            for file in files:\n",
        "                # Create the correct file path within the zip file\n",
        "                file_path = os.path.join(root, file)\n",
        "                arcname = os.path.relpath(file_path, os.path.dirname(folder_path))\n",
        "                zipf.write(file_path, arcname=arcname)\n",
        "\n",
        "# Paths\n",
        "folder_path = '/content/car-license-plate-detection-iran_mscoco'  # Replace with the actual path to the folder\n",
        "output_zip = 'License_detection.zip'\n",
        "\n",
        "# Create zip\n",
        "zip_dataset(folder_path, output_zip)\n",
        "print(f\"{output_zip} created successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwyodOjtwoS-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVOhjZdAwoS_"
      },
      "source": [
        "# Import the Dataset to the project\n",
        "\n",
        "\n",
        "1.   Upload the dataset\n",
        "2.   Start a data import action\n",
        "3.   Check the status of the dataset import action\n",
        "4.   Check the processed dataset information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa5cw14JwoS_"
      },
      "source": [
        "Upload the dataset\n",
        "\n",
        "For uploading the dataset you have 2 options:-\n",
        "\n",
        "\n",
        "*   Upload the dataset to cloud storage bucket with `project.upload_cloud_dataset()`\n",
        "*   Upload the dataset from your local storage with `project.upload_local_dataset() `"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtT4a_XFwoS_"
      },
      "outputs": [],
      "source": [
        "dataset, dataset_action = project_instance.import_local_dataset(\n",
        "    dataset_name='Licence Plate detection',\n",
        "    file_path = r\"/content/License_detection.zip\",\n",
        "    dataset_type = \"detection\",\n",
        "    dataset_description = \"Licence plate detection dataset\",\n",
        "    version_description = \"1st version\",\n",
        "    input_type = \"image\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLmfruoewoS_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1bgDszpwoS_"
      },
      "outputs": [],
      "source": [
        "dataset_id = dataset.dataset_id\n",
        "action_id = dataset_action.action_id\n",
        "\n",
        "print(f\"Dataset ID: {dataset_id}\")\n",
        "print(f\"Action ID: {action_id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xk_EGK3woS_"
      },
      "outputs": [],
      "source": [
        "Vars.set(\"dataset_id\", dataset.dataset_id)\n",
        "Vars.set(\"dataset_action_id\", dataset_action.action_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swdhQHunwoS_"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import pprint\n",
        "\n",
        "action_id = dataset_action.action_id\n",
        "def check_dataset_status():\n",
        "    while True:\n",
        "        print(\" \")\n",
        "        print(\"-------Status------\")\n",
        "        D = Dataset(session_instance, dataset_id=dataset_id)\n",
        "        status = D.version_status\n",
        "        print(\"Status of dataset:\", status)\n",
        "        print(\"-------------------\")\n",
        "        if status == 'processed':\n",
        "            print(\"---------Preprocesing Complete---------\")\n",
        "            print(\"Dataset processed, proceed with experiment creation.\")\n",
        "            print(\"---------------------------------------\")\n",
        "            break\n",
        "\n",
        "        time.sleep(90)  # Wait for 90 seconds before checking again\n",
        "\n",
        "# Run the function to check dataset status\n",
        "check_dataset_status()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nm2GDgkPwoTA"
      },
      "outputs": [],
      "source": [
        "def print_dataset_info(dataset):\n",
        "\n",
        "    dataset_id = dataset.dataset_details['_id']\n",
        "    dataset_name = dataset.dataset_details['name']\n",
        "    version_status = dataset.dataset_details.get(\"stats\", [{}])[0].get(\"versionStatus\")\n",
        "    latest_version = dataset.dataset_details['latestVersion']\n",
        "    no_of_samples = sum(version['versionStats']['total'] for version in dataset.dataset_details.get('stats', []))\n",
        "    no_of_classes = len(dataset.dataset_details.get('stats', [{}])[0].get('classStat', {}))\n",
        "    no_of_versions = len(dataset.dataset_details.get('allVersions', []))\n",
        "    last_updated_at = dataset.dataset_details.get('updatedAt')\n",
        "\n",
        "    print(f\"Dataset ID: {dataset_id}\")\n",
        "    print(f\"Dataset Name: {dataset_name}\")\n",
        "    print(f\"Version Status: {version_status}\")\n",
        "    print(f\"Latest Version: {latest_version}\")\n",
        "    print(f\"Number of Samples: {no_of_samples}\")\n",
        "    print(f\"Number of Classes: {no_of_classes}\")\n",
        "    print(f\"Number of Versions: {no_of_versions}\")\n",
        "    print(f\"Last Updated At: {last_updated_at}\")\n",
        "\n",
        "dataset.refresh()\n",
        "print_dataset_info(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RJWcaljwoTA"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "pprint.pprint(dataset.summary)\n",
        "dataset_summary = dataset.summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIFF2n_zwoTA"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "import pandas as pd\n",
        "import plotly.io as pio\n",
        "\n",
        "\n",
        "# Convert the histogram data to a DataFrame\n",
        "df = pd.DataFrame(dataset_summary['histogram'])\n",
        "\n",
        "# Bar chart for counts by category\n",
        "fig1 = go.Figure(data=[go.Bar(x=df['label'], y=df['count'])])\n",
        "fig1.update_layout(\n",
        "    title='Count of Items by Category',\n",
        "    xaxis_title='Category',\n",
        "    yaxis_title='Count'\n",
        ")\n",
        "\n",
        "# Pie chart for distribution of data items\n",
        "fig2 = go.Figure(data=[go.Pie(\n",
        "    labels=['Test', 'Train', 'Unassigned', 'Validation'],\n",
        "    values=[dataset_summary['testDataItemCount'], dataset_summary['trainDataItemCount'], dataset_summary['unassignedDataItemCount'], dataset_summary['valDataItemCount']],\n",
        "    hole=0.3\n",
        ")])\n",
        "fig2.update_layout(\n",
        "    title='Distribution of Data Items'\n",
        ")\n",
        "\n",
        "# Display the figures\n",
        "fig1.show()\n",
        "fig2.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFJAsPAVwoTB"
      },
      "source": [
        "# Create a Model Training experiment\n",
        "\n",
        "1.   Start a Model Training experiment\n",
        "2.   Explore the available SOTA model families and models\n",
        "3.   Get the default training config , modify it if needed.\n",
        "4.   Add the model for training.\n",
        "5.   Check for the status of the model train action"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBt_3eLVwoTB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import pprint\n",
        "import uuid\n",
        "\n",
        "# Generate a unique experiment name\n",
        "experiment_name_user = f\"Vehicle-detection-experiment-{uuid.uuid4()}\"\n",
        "\n",
        "# Function to create an experiment\n",
        "def create_experiment():\n",
        "    name = experiment_name_user\n",
        "    target_run_time = [\"PyTorch\"]\n",
        "    primary_metric = \"precision\"\n",
        "    matrice_compute = True\n",
        "    dataset_version = 'v1.0'\n",
        "\n",
        "    experiment_instance = project_instance.create_experiment(\n",
        "        name,\n",
        "        dataset_id,\n",
        "        target_run_time[0],\n",
        "        dataset_version,\n",
        "        primary_metric,\n",
        "        matrice_compute\n",
        "    )\n",
        "\n",
        "    print(experiment_instance)\n",
        "    experiment_id = experiment_instance.experiment_id\n",
        "    experiment_name = experiment_instance.experiment_name\n",
        "\n",
        "    print(f\"Experiment ID: {experiment_id}\")\n",
        "    print(f\"Experiment Name: {experiment_name}\")\n",
        "\n",
        "    return experiment_instance, experiment_id, experiment_name\n",
        "\n",
        "# Create a new experiment\n",
        "experiment_instance , experiment_id, experiment_name = create_experiment()\n",
        "\n",
        "print(\"----------------------------\")\n",
        "print(f\"Experiment ID: {experiment_id}\")\n",
        "print(f\"Experiment Name: {experiment_name}\")\n",
        "print(f\"Experiment instance has been created: {experiment_instance}\")\n",
        "print(\"----------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxVymPCnwoTB"
      },
      "outputs": [],
      "source": [
        "Vars.set(\"experiment_id\", experiment_instance.experiment_id)\n",
        "Vars.set(\"experiment_name\", experiment_instance.experiment_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlxfL0i-woTC"
      },
      "outputs": [],
      "source": [
        "from matrice.model_store import _get_all_model_families\n",
        "\n",
        "resp , error , mesage = _get_all_model_families( session_instance , project_id , project_type=\"detection\" )\n",
        "print(\"----List of available classification models on platform----\")\n",
        "# Iterate through each model family in the response\n",
        "for model_family in resp:\n",
        "    # Extract _id and modelFamily (model family name)\n",
        "    model_family_id = model_family.get('_id')\n",
        "    name = model_family.get('modelFamily')\n",
        "\n",
        "    # Print in formatted manner\n",
        "    print(f\"ID: {model_family_id}, Model Family Name: {name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SurPRL-uwoTC"
      },
      "outputs": [],
      "source": [
        "from matrice.model_store import ModelFamily\n",
        "\n",
        "model_family_id = \"65c677355f34a0e8878e3f05\"\n",
        "# Initialize the ModelFamily instance after choosing a Model Family\n",
        "model_family_instance = ModelFamily(session_instance, model_family_id=model_family_id) # Update with the model family ID of your choice\n",
        "print(\"A ModelFamily instance has been initialized\",model_family_instance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ha-rYbSSwoTC"
      },
      "outputs": [],
      "source": [
        "# Fetch model architectures\n",
        "arch_resp, error, message = model_family_instance.get_model_archs()\n",
        "if error:\n",
        "    print(f\"Error: {error}\")\n",
        "else:\n",
        "\n",
        "    # Check if resp is a list or a dictionary\n",
        "    if isinstance(arch_resp, list):\n",
        "        # Iterate through each model info in the list\n",
        "        for model_info in arch_resp:\n",
        "            model_key = model_info[\"model_key\"]\n",
        "            model_arch_instance = model_info[\"model_arch_instance\"]\n",
        "\n",
        "            # Extract model information\n",
        "            model_info_id = model_arch_instance.model_info_id\n",
        "            name = model_arch_instance.model_name\n",
        "            key = model_arch_instance.model_key\n",
        "            params = model_arch_instance.params_millions\n",
        "\n",
        "            # Print in formatted manner\n",
        "            print(f\"ID: {model_info_id} |  Model Name: {name} | Model Key: {key} | Params in Millions: {params}\")\n",
        "    elif isinstance(arch_resp, dict):\n",
        "        # Iterate through each model key in the dictionary\n",
        "        for model_key, model_arch_instance in arch_resp.items():\n",
        "            # Extract model information\n",
        "            model_info_id = model_arch_instance.model_info_id\n",
        "            name = model_arch_instance.model_name\n",
        "            key = model_arch_instance.model_key\n",
        "            params = model_arch_instance.params_millions\n",
        "\n",
        "            # Print in formatted manner\n",
        "            print(f\"ID: {model_info_id} | Model Name: {name} | Model Key: {key} | Params in Millions: {params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tItL6T2nwoTD"
      },
      "outputs": [],
      "source": [
        "from matrice.model_store import ModelArch\n",
        "train_arch = 'yolov8m' # Update with the model key of your choice\n",
        "print(\"Chosen Training Architecture :\" ,train_arch)\n",
        "model_arch_instance = arch_resp.get(train_arch)\n",
        "print(\"Model Architecture instance initialized for chosen training architecture :\", model_arch_instance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLZdtCN0woTD"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "train_instance , train_config = model_arch_instance.get_train_config(experiment_id=Vars.get('experiment_id'))\n",
        "print(\"-----Default Train Config------\")\n",
        "pprint.pprint(train_config)\n",
        "print(\"--------------------------------\")\n",
        "print(\"-------Training instance initialized--------\")\n",
        "print(train_instance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uj1JSmMgwoTD"
      },
      "outputs": [],
      "source": [
        "model_config = train_config['model_config']\n",
        "\n",
        "# Modify the model_config as needed\n",
        "# modifications:\n",
        "model_config['batch_size'] = [4]\n",
        "model_config['epochs'] = [100]\n",
        "model_config['learning_rate'] = [0.001]\n",
        "\n",
        "\n",
        "# Repass the modified model_config into the train_config\n",
        "train_config['model_config'] = model_config\n",
        "\n",
        "# Print the updated train_config\n",
        "print(\"-----Updated Model Config------\")\n",
        "pprint.pprint(train_config['model_config'])\n",
        "print(\"--------------------------------\")\n",
        "\n",
        "# Print the updated train_config\n",
        "print(\"-----Updated Train Config------\")\n",
        "pprint.pprint(train_config)\n",
        "print(\"--------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HN5rFSFwoTE"
      },
      "outputs": [],
      "source": [
        "train_resp , msg , err = experiment_instance.add_models_for_training(train_instance,train_config)\n",
        "print(\"------------Model added for training----------\")\n",
        "pprint.pprint(train_resp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIkXXN9lwoTE"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from matrice.action import Action\n",
        "\n",
        "# Define the action ID and the status you want to check\n",
        "action_id = train_resp[0]['_idActionStatus']\n",
        "success_status = 'SUCCESS'\n",
        "\n",
        "# Function to check the status of the action\n",
        "def check_action_status(S, action_id):\n",
        "    action_instance = Action(S, action_id)\n",
        "    print(\"---------------------\")\n",
        "    print(f\"Action ID: {action_id}\")\n",
        "    print(f\"Current Status: {action_instance.status}\")\n",
        "    print(f\"Step Code: {action_instance.step_code}\")\n",
        "    print(f\"Action service is : {action_instance.service_name}\")\n",
        "    print(\"---------------------\")\n",
        "    return action_instance.status\n",
        "\n",
        "# Loop to check status every 2 minutes until it is 'success'\n",
        "while True:\n",
        "    status = check_action_status(session_instance, action_id)\n",
        "    if status == success_status:\n",
        "        print(\"Action status is 'success'. Model is successfully trained.\")\n",
        "        break\n",
        "    else:\n",
        "        print(\"Model is training. Waiting 10 minutes before checking again.\")\n",
        "        time.sleep(200)  # Wait for 10 minutes (600 seconds)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2O5X7SmjwoTE"
      },
      "source": [
        "# Check the performance of the Trained Model\n",
        "\n",
        "*   Check the performance values\n",
        "*   Plot the epochs details of the model\n",
        "*   Get the evaluation results of the model\n",
        "*   Downlaod the trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFLx2dphwoTE"
      },
      "outputs": [],
      "source": [
        "model_id = train_resp[0]['_id']\n",
        "print(f\"Model ID from response data: {model_id}\")\n",
        "\n",
        "\n",
        "# Initialize the Model class with the model_id\n",
        "model_instance = Model(session_instance, model_id)\n",
        "print(\"A Model instance has been initialized : \", model_instance)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_instance)"
      ],
      "metadata": {
        "id": "1h3rwEC5SupK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_h0PB3KwoTF"
      },
      "outputs": [],
      "source": [
        "Vars.set(\"model_train_id\", model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AAWOtOuwoTF"
      },
      "outputs": [],
      "source": [
        "# Print the test score, validation score, and best epoch\n",
        "print(f\"Test Score: {model_instance.test_score}\")\n",
        "print(f\"Validation Score: {model_instance.val_score}\")\n",
        "print(f\"Best Epoch: {model_instance.best_epoch}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmoPm39lwoTF"
      },
      "outputs": [],
      "source": [
        "model_instance.plot_epochs_losses()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2p24LNq-woTF"
      },
      "outputs": [],
      "source": [
        "model_instance.plot_epochs_metrics()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmz4pIWUwoTF"
      },
      "outputs": [],
      "source": [
        "model_instance.plot_eval_results()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xUEXqdJwoTG"
      },
      "source": [
        "## Get test predictions on random samples from test set from the trained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lw0Fxb-ewoTH"
      },
      "source": [
        "## Detection Pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1TY_fFhwoTH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import requests\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "\n",
        "# Define the folder path containing the images\n",
        "folder_path = r\"/content/images_test\"\n",
        "\n",
        "\n",
        "# Get a list of all image files in the folder\n",
        "image_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "# Randomly select 10 images from the folder\n",
        "random_images = random.sample(image_files, 1)\n",
        "\n",
        "\n",
        "# Loop through the selected images and send the prediction request\n",
        "for image_file in random_images:\n",
        "\n",
        "    result, error, message = model_instance.get_prediction(image_file)\n",
        "\n",
        "    if error:\n",
        "        print(f\"Error: {error}\")\n",
        "        continue\n",
        "\n",
        "    # Extract prediction data from the result\n",
        "    predictions = result\n",
        "\n",
        "    # Open the image\n",
        "    image = Image.open(image_file)\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    fig, ax = plt.subplots(1)\n",
        "    ax.imshow(image)\n",
        "\n",
        "    # Draw bounding boxes and labels\n",
        "    for prediction in predictions:\n",
        "        category = prediction[\"category\"]\n",
        "        confidence = prediction[\"confidence\"]\n",
        "        bbox = prediction[\"bounding_box\"]\n",
        "\n",
        "        # Extract the bounding box coordinates\n",
        "        xmin, ymin, xmax, ymax = bbox[\"xmin\"], bbox[\"ymin\"], bbox[\"xmax\"], bbox[\"ymax\"]\n",
        "        width, height = xmax - xmin, ymax - ymin\n",
        "\n",
        "        # Create a Rectangle patch\n",
        "        rect = plt.Rectangle((xmin, ymin), width, height, linewidth=2, edgecolor='r', facecolor='none')\n",
        "        ax.add_patch(rect)\n",
        "        plt.text(xmin, ymin, f\"{category} ({confidence:.2f})\", bbox=dict(facecolor='yellow', alpha=0.5))\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2QUI-xlxnLRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSrGoWB7woTH"
      },
      "outputs": [],
      "source": [
        "model_instance.download_model(file_name=\"model.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkH-Ah2GwoTI"
      },
      "source": [
        "# Export the model based on usage and platform and optimzie the Model Export\n",
        "\n",
        "\n",
        "1.   Create a model export action using the export config\n",
        "2.   Check the status of the model export action\n",
        "3.   Download the exported model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cC_JBIL8woTI"
      },
      "outputs": [],
      "source": [
        "export_config = train_instance.get_default_export_config(\"ONNX\") # Get the default export config for export format user wants (here ONNX)\n",
        "print(\"Export Config for ONNX:\")\n",
        "pprint.pprint(export_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D81sWhd0woTI"
      },
      "outputs": [],
      "source": [
        "exported_instance , action_instance = project_instance.create_model_export(model_id,\"ONNX\",export_config)\n",
        "\n",
        "print(\"Model Export class has been initialized :\", exported_instance)\n",
        "print(\"----------------------------\")\n",
        "print(f\"Export ID: {exported_instance.model_export_id}\")\n",
        "print(f\"Export Name: {exported_instance.model_export_name}\")\n",
        "print(f\"Action ID: {action_instance.action_id}\")\n",
        "print(f\"Action Status: {action_instance.status}\")\n",
        "print(\"----------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmOjp7w7woTI"
      },
      "outputs": [],
      "source": [
        "Vars.set(\"model_export_id\", exported_instance.model_export_id)\n",
        "Vars.set(\"model_export_name\", exported_instance.model_export_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaXx0urJwoTI"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from matrice.action import Action\n",
        "\n",
        "# Define the action ID and the status you want to check\n",
        "action_id = action_instance.action_id\n",
        "success_status = 'SUCCESS'\n",
        "\n",
        "# Function to check the status of the action\n",
        "def check_action_status(S, action_id):\n",
        "    A = Action(S, action_id)\n",
        "    print(\"---------------------\")\n",
        "    print(f\"Action ID: {action_id}\")\n",
        "    print(f\"Current Status: {A.status}\")\n",
        "    print(f\"Step Code: {A.step_code}\")\n",
        "    print(f\"Action service is : {A.service_name}\")\n",
        "    print(\"---------------------\")\n",
        "    return A.status\n",
        "\n",
        "# Loop to check status every 1.5 minutes until it is 'success'\n",
        "while True:\n",
        "    status = check_action_status(session_instance, action_id)\n",
        "    if status == success_status:\n",
        "        print(\"Action status is 'success'. Model is successfully exported.\")\n",
        "        break\n",
        "    else:\n",
        "        print(\"Model is exporting. Waiting 2 minutes before checking again.\")\n",
        "        time.sleep(90)  # Wait for 1.5 minutes (90 seconds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ou7k4zqpwoTI"
      },
      "outputs": [],
      "source": [
        "exported_instance.download_model(file_name=\"model.onnx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sR4WwhIbwoTJ"
      },
      "source": [
        "# Deploy the Model on Cloud\n",
        "\n",
        "1.   Start a Model Deployment server\n",
        "2.   Make Predictions on the Deployed Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpXOs7qbwoTJ"
      },
      "outputs": [],
      "source": [
        "deployment , deployment_action = project_instance.create_deployment(\n",
        "    model_id = Vars.get('model_train_id'),  # It can also be model_train_id depending on the model you want to deploy\n",
        "    deployment_name = \"vehicle-detection\",\n",
        "    shutdown_threshold=20\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wx_ONa_XwoTJ"
      },
      "outputs": [],
      "source": [
        "key_resp = deployment.create_auth_key(10)\n",
        "auth_key = key_resp[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBmeztsHwoTJ"
      },
      "outputs": [],
      "source": [
        "Vars.set(\"deployment_id\", deployment.deployment_id)\n",
        "Vars.set(\"deployment_name\", deployment.deployment_name)\n",
        "Vars.set(\"auth_key\", auth_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kc6wkP4pwoTK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import requests\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "\n",
        "# Define the folder path containing the images\n",
        "folder_path = r\"/content/images_test\"\n",
        "\n",
        "\n",
        "# Get a list of all image files in the folder\n",
        "image_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "# Randomly select 10 images from the folder\n",
        "random_images = random.sample(image_files, 1)\n",
        "\n",
        "\n",
        "# Loop through the selected images and send the prediction request\n",
        "for image_file in random_images:\n",
        "    # Check if image_file is a valid path\n",
        "    if not isinstance(image_file, str):\n",
        "        print(f\"Invalid image path: {image_file}\")\n",
        "        continue\n",
        "\n",
        "    # Send prediction request\n",
        "    result, error, message = deployment.get_prediction(auth_key, image_file)\n",
        "\n",
        "    if error:\n",
        "        print(f\"Error: {error}\")\n",
        "        continue\n",
        "\n",
        "    # Extract prediction data from the result\n",
        "    predictions = result\n",
        "\n",
        "    # Open the image\n",
        "    image = Image.open(image_file)\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    fig, ax = plt.subplots(1)\n",
        "    ax.imshow(image)\n",
        "\n",
        "    # Draw bounding boxes and labels\n",
        "    for prediction in predictions:\n",
        "        category = prediction[\"category\"]\n",
        "        confidence = prediction[\"confidence\"]\n",
        "        bbox = prediction[\"bounding_box\"]\n",
        "\n",
        "        # Extract the bounding box coordinates\n",
        "        xmin, ymin, xmax, ymax = bbox[\"xmin\"], bbox[\"ymin\"], bbox[\"xmax\"], bbox[\"ymax\"]\n",
        "        width, height = xmax - xmin, ymax - ymin\n",
        "\n",
        "        # Create a Rectangle patch\n",
        "        rect = plt.Rectangle((xmin, ymin), width, height, linewidth=2, edgecolor='r', facecolor='none')\n",
        "        ax.add_patch(rect)\n",
        "        plt.text(xmin, ymin, f\"{category} ({confidence:.2f})\", bbox=dict(facecolor='yellow', alpha=0.5))\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AYPUmY4iv_qy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}